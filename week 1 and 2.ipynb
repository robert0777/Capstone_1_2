{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Week 1 and 2 "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - geopy\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    geographiclib-1.50         |             py_0          34 KB  conda-forge\n    geopy-1.21.0               |             py_0          58 KB  conda-forge\n    openssl-1.1.1f             |       h516909a_0         2.1 MB  conda-forge\n    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n    ca-certificates-2020.4.5.1 |       hecc5488_0         146 KB  conda-forge\n    certifi-2020.4.5.1         |   py36h9f0ad1d_0         151 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.5 MB\n\nThe following NEW packages will be INSTALLED:\n\n    geographiclib:   1.50-py_0         conda-forge\n    geopy:           1.21.0-py_0       conda-forge\n    python_abi:      3.6-1_cp36m       conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2020.1.1-0                    --> 2020.4.5.1-hecc5488_0     conda-forge\n    certifi:         2020.4.5.1-py36_0             --> 2020.4.5.1-py36h9f0ad1d_0 conda-forge\n    openssl:         1.1.1f-h7b6447c_0             --> 1.1.1f-h516909a_0         conda-forge\n\n\nDownloading and Extracting Packages\ngeographiclib-1.50   | 34 KB     | ##################################### | 100% \ngeopy-1.21.0         | 58 KB     | ##################################### | 100% \nopenssl-1.1.1f       | 2.1 MB    | ##################################### | 100% \npython_abi-3.6       | 4 KB      | ##################################### | 100% \nca-certificates-2020 | 146 KB    | ##################################### | 100% \ncertifi-2020.4.5.1   | 151 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nSolving environment: \\ "
                }
            ],
            "source": "# Import libraries\nimport numpy as np # library to handle data in a vectorized manner\nimport json # library to handle JSON files\nimport pandas as pd\n\n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nfrom bs4 import BeautifulSoup\n\n# Import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes \nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Download the dataset and read it into a pandas dataframe.\n\n# The Arrondissements dataset was downloaded from Paris|DATA:  https://opendata.paris.fr/explore/dataset/arrondissements/table/?dataChart\n# Then placed on the GitHub repo for the project.\n# https://raw.githubusercontent.com/AR-data-science/Coursera_Capstone/master/Arrondissements_.csv\n\nparis = pd.read_csv('https://raw.githubusercontent.com/AR-data-science/Coursera_Capstone/master/Arrondissements_.csv')\nparis"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Rename the necessary columns 'Geometry_X and Geometry_Y' etc...\n\n# District : name of the central District for the Arrondissement\n# Arrondissement : the Arrondissement or district number which is used to identify it\n# Arrondissement_Fr : the descriptive French label for each Arrondissement\n\nparis.rename(columns={'NAME': 'Neighborhood ', 'CAR': 'Arrondissement_Num', 'Geometry_X': 'Latitude', 'Geometry_Y': 'Longitude',  'LAR': 'French_Name'}, inplace=True)\nparis"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Clean up the dataset to remove unnecessary columns.\n# Some of the columns are for mapping software - not required here.\n\nparis.drop(['NSQAR','CAR.1','CARINSEE','NSQCO','SURFACE', 'PERIMETRE' ], axis=1, inplace=True)\nparis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Week 1 and 2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Check the shape of the dataframe\nparis.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Retrieve the Latitude and Longitude for Paris\nfrom geopy.geocoders import Nominatim \n\naddress = 'Paris'\n\n# Define the user_agent as Paris_explorer\ngeolocator = Nominatim(user_agent=\"Paris_explorer\")\n\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\n\nprint('The geographical coordinates of Paris France are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# create map of Paris using the above latitude and longitude values\nmap_paris = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n\n# add markers to map\nfor lat, lng, label in zip(paris['Latitude'], paris['Longitude'], paris['French_Name']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=25,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.3,\n        parse_html=False).add_to(map_paris)  \n    \nmap_paris"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nCLIENT_ID = 'RU3Y3XCL1D3X4IFWHEPI3VYYAEEGSWMVQTWP2PHZ1DEL1E2R' # your Foursquare ID\nCLIENT_SECRET = 'GMMPCVSMWDJDXSOTEO22G3FN4H2BUFSZO05SYEGRGW4N5AKL' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Explore the first Neighborhood in our dataframe.\n# Get the Neighborhood's French name.\n\nparis.loc[0, 'French_Name']\nparis.loc[0, 'French_Name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Get the Neighborhood's latitude and longitude values.\n\nneighborhood_latitude = paris.loc[0, 'Latitude'] # Neighborhood latitude value\nneighborhood_longitude = paris.loc[0, 'Longitude'] # Neighborhood longitude value\n\nneighborhood_name = paris.loc[0, 'French_Name'] # Neighborhood name\n\nprint('Latitude and longitude values of the neighborhood {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\n\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\nurl # displays the URL"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Send the GET request and examine the resutls\n\nresults = requests.get(url).json()\nresults"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# define a function that extracts the category of the venue\n\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# clean the json and structure it into a pandas dataframe.\n\nvenues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head(20)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Check how many venues there are in 3eme Ardt within a radius of 500 meters\n\nprint('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['French_Name', \n                  'Latitude', \n                  'Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Create a new dataframe called paris_venues.\n\nparis_venues = getNearbyVenues(names=paris['French_Name'],\n                                   latitudes=paris['Latitude'],\n                                   longitudes=paris['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(paris_venues.shape)\nparis_venues.head(250)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "paris_venues.groupby('French_Name').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Calculate how many unique categories there are.\nprint('There are {} unique venue categories.'.format(len(paris_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Analyze each of the Neighborhoods from the results\n\n# one hot encoding\nparis_onehot = pd.get_dummies(paris_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nparis_onehot['Neighborhood'] = paris_venues['French_Name'] \n\n# move neighborhood column to the first column\nfixed_columns = [paris_onehot.columns[-1]] + list(paris_onehot.columns[:-1])\nparis_onehot = paris_onehot[fixed_columns]\n\nparis_onehot"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The shape of the dataframe is\nparis_onehot.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "paris_grouped = paris_onehot.groupby('Neighborhood').mean().reset_index()\nparis_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The shape of the grouped data is\nparis_grouped.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Each  neighborhood with top 10 most common venues\n\nnum_top_venues = 10\n\nfor hood in paris_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = paris_grouped[paris_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# First sort the venues in descending order.\n\ndef return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## The top 10 venue categories for each neighborhood This is a very useful results table that can provide at a glance information for all of the districts. Even once any conclusions are drawn further into the data workflow, we can refer back to this table for meaaningful insights about the top categories of businesses in all the neighbourhoods. Even without actual counts and numbers, it makes a great reference table for the client."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create the new dataframe and display the top 10 venues for each neighborhood\n\nnum_top_venues = 10\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n        \n# create a new dataframe\nparis_venues_sorted = pd.DataFrame(columns=columns)\nparis_venues_sorted['Neighborhood'] = paris_grouped['Neighborhood']\n\nfor ind in np.arange(paris_grouped.shape[0]):\n    paris_venues_sorted.iloc[ind, 1:] = return_most_common_venues(paris_grouped.iloc[ind, :], num_top_venues)\n\nparis_venues_sorted.head(20)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The shape of the sorted data is\nparis_venues_sorted.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Categorical plot\n# Explore a plot of this data (a violin plot is used which is a density estimation of the underlying distribution).\n# The top 3 venue types as specified by the client for each neighborhood are used for the plotting.\n\nimport seaborn as sns\n\nfig = plt.figure(figsize=(50,25))\nsns.set(font_scale=1.1)\n\nax = plt.subplot(3,1,1)\nsns.violinplot(x=\"Neighborhood\", y=\"French Restaurant\", data=paris_onehot, cut=0);\nplt.xlabel(\"\")\n\nax = plt.subplot(3,1,2)\nsns.violinplot(x=\"Neighborhood\", y=\"Caf\u00e9\", data=paris_onehot, cut=0);\nplt.xlabel(\"\")\n\nplt.subplot(3,1,3)\nsns.violinplot(x=\"Neighborhood\", y=\"Wine Bar\", data=paris_onehot, cut=0);\n\nax.text(-1.0, 3.1, 'Frequency distribution for the top 3 venue categories for each neighborhood (click to enlage)', fontsize=60)\nplt.savefig (\"Distribution_Frequency_Venues_3_categories.png\", dpi=240)\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## The Neighborhoods\nSo as we can see from the analysis there are 8 neighborhoods to open new stores - according to the criteria that they have the 3 specified venues in a great frequency (French Restaurants, Caf\u00e9s and Wine Bars). They are as follows:\n* 3eme Ardt\n* 10eme Ardt\n* 11eme Ardt\n* 4eme Ardt\n* 18eme Ardt\n* 18eme Ardt\n* 5eme Ardt\n* 9eme Ardt\n* 6eme Ardt\n\nLet's take this further with some exploration and Inferential Analysis\nWe have the 8 neighborhoods that all include the venue category criteria. But if we included the 'Clothing_Store\" venue category into the analysis, then we might be able to make some inferences based on the data, and domain knowledge of marketing and the industry, to focus the list"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Add the Clothing_Store to explore this category\nimport seaborn as sns\n\nfig = plt.figure(figsize=(50,15))\nsns.set(font_scale=1.1)\n\nax = plt.subplot(1,1,1)\nsns.violinplot(x=\"Neighborhood\", y=\"Clothing Store\", data=paris_onehot, cut=0);\nplt.xlabel(\"\")\n\nax.text(1.0, 1.1, 'Frequency of Clothing stores for each neighborhood', fontsize=60)\nplt.savefig (\"Distribution_Frequency_Clothing_Venues.png\", dpi=240)\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Clothing_Store has been added to explore this category and make a comparison\n\nimport seaborn as sns\n\nfig = plt.figure(figsize=(50,25))\nsns.set(font_scale=1.1)\n\nax = plt.subplot(4,1,1)\nsns.violinplot(x=\"Neighborhood\", y=\"French Restaurant\", data=paris_onehot, cut=0);\nplt.xlabel(\"\")\n\nax = plt.subplot(4,1,2)\nsns.violinplot(x=\"Neighborhood\", y=\"Caf\u00e9\", data=paris_onehot, cut=0);\nplt.xlabel(\"\")\n\nplt.subplot(4,1,3)\nsns.violinplot(x=\"Neighborhood\", y=\"Wine Bar\", data=paris_onehot, cut=0);\n\nplt.subplot(4,1,4)\nsns.violinplot(x=\"Neighborhood\", y=\"Clothing Store\", data=paris_onehot, cut=0);\n\nax.text(-1.0, 3.1, 'Frequency distribution for the top 3 venue categories for each neighborhood (includes clothing)', fontsize=60)\nplt.savefig (\"Distribution_Frequency_Venues_3_categories_clothing.png\", dpi=240)\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n## 4 Inferences and Discussion\n\nChosen Neighborhoods - Results Inferential analysis using the data, as well as domain knowledge of retail and marketing, allow the list to be focussed to just 3 neighbourhoods from the previous 8.\nThe reasoning being that if the 3 criteria have been met - identifying neighbourhoods that are lively with Restaurants, Caf\u00e9s and Wine Bars - adding Clothing Stores into the mix of stores in the area is a significant bonus. Having some of the same category of stores in the same area - especially in fashion retail - is very desirable as a retailer.\nSo we can increase the criteria to include Restaurants, Caf\u00e9s, Wine Bars and Clothing Stores - which narrows down and focuses the suggested districts for new stores to be located, and at the same time provides better locations for the brand.\nSo the final 3 prospective neighborhoods for new store locations are where 4 criteria are met:\n\n* 3eme Ardt : Arrondissement 3, Temple\n* 4eme Ardt : Arrondissement 4, Hotel-de-Ville\n* 6eme Ardt : Arrondissement 6, Luxembourg"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The csv of the 3 chosen prospective neighborhoods was uploaded to GitHub for access and reference\n# Download and put into a new dataframe called chosen_districts\n\nchosen_districts = pd.read_csv('https://raw.githubusercontent.com/AR-data-science/Coursera_Capstone/master/Week%205/Chosen.csv')\nchosen_districts"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Create a folium map of Paris with the 3 neighborhoods superimposed on the map\nmap_chosen_districts = folium.Map(location=[latitude, longitude], zoom_start=13)\n\n# add markers to map\nfor lat, lng, label in zip(chosen_districts['Latitude'], chosen_districts['Longitude'], chosen_districts['French_Name']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=45,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.2,\n        parse_html=False).add_to(map_chosen_districts)  \n    \nmap_chosen_districts"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "map_chosen_districts = folium.Map(location=[latitude, longitude], zoom_start=15)\n\n# add markers to map\nfor lat, lng, label in zip(chosen_districts['Latitude'], chosen_districts['Longitude'], chosen_districts['French_Name']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=130,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.2,\n        parse_html=False).add_to(map_chosen_districts)  \n    \nmap_chosen_districts"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}